# models/multimodal_aln.py
import torch
import torch.nn as nn
from transformers import Wav2Vec2Model, T5ForConditionalGeneration, Wav2Vec2Config

class ALMModel(nn.Module):
    def __init__(self, wav2vec_model="facebook/wav2vec2-base-960h", t5_model="t5-small", num_audio_labels=527):
        super().__init__()
        self.wav2vec = Wav2Vec2Model.from_pretrained(wav2vec_model)
        # AED head (simple pooling + classifier)
        hidden = self.wav2vec.config.hidden_size
        self.aed_head = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Linear(hidden, num_audio_labels)  # multi-label score logits
        )
        # ASR head (CTC) optional - can use wav2vec + linear to vocab
        # For QA text generation use T5 conditioned on audio pooled embedding
        self.t5 = T5ForConditionalGeneration.from_pretrained(t5_model)
        # map audio embedding to decoder initial state via adapter
        self.adapter = nn.Linear(hidden, self.t5.config.d_model)
    def forward(self, input_values, attention_mask=None, labels=None, aed_targets=None):
        # input_values: float tensor (batch, seq_len)
        x = self.wav2vec(input_values, attention_mask=attention_mask).last_hidden_state  # (B, T, H)
        # AED: do pooling across time
        pooled = x.mean(dim=1)  # (B,H)
        aed_logits = self.aed_head(pooled.unsqueeze(-1))  # adjust shapes if needed
        outputs = {}
        if aed_targets is not None:
            # BCEWithLogitsLoss for multi-label
            loss_f = nn.BCEWithLogitsLoss()
            outputs['aed_loss'] = loss_f(aed_logits, aed_targets)
        if labels is not None:
            # For T5 conditional generation: provide text input via forced decoder input
            # We'll map pooled audio into encoder states by prepending a prefix token embedding approach (simplified)
            # Simpler: generate a prefix string and pass to t5 â€” here show as placeholder
            encoder_embedding = self.adapter(pooled).unsqueeze(1)  # (B,1,d_model)
            # NOTE: Proper conditioning requires more involved fusion; this is a placeholder.
            # For training QA, you can create text prefix like "<audio_embedding> " and fine-tune T5.
            pass
        outputs['aed_logits'] = aed_logits
        return outputs
